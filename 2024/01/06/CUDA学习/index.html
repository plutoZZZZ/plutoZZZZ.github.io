<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="谭升的博客CUDA编程入门极简教程CUDA 矩阵乘法终极优化指南安装CUDA开发环境搭建CUDA入门示例1：两个整型数组相加 异构计算 GPU的ALU更多，逻辑控制单元更少 123456789101112131415&#x2F;**hello_world.cu*&#x2F;#include&lt;stdio.h&gt;__global__ void hello_world(void)&#123;  printf(&amp;q">
<meta property="og:type" content="article">
<meta property="og:title" content="CUDA">
<meta property="og:url" content="http://example.com/2024/01/06/CUDA%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="Lusz的博客">
<meta property="og:description" content="谭升的博客CUDA编程入门极简教程CUDA 矩阵乘法终极优化指南安装CUDA开发环境搭建CUDA入门示例1：两个整型数组相加 异构计算 GPU的ALU更多，逻辑控制单元更少 123456789101112131415&#x2F;**hello_world.cu*&#x2F;#include&lt;stdio.h&gt;__global__ void hello_world(void)&#123;  printf(&amp;q">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2024/01/06/CUDA%E5%AD%A6%E4%B9%A0/image2.png">
<meta property="og:image" content="http://example.com/2024/01/06/CUDA%E5%AD%A6%E4%B9%A0/image.jpeg">
<meta property="og:image" content="http://example.com/2024/01/06/CUDA%E5%AD%A6%E4%B9%A0/image1.jpeg">
<meta property="og:image" content="http://example.com/2024/01/06/CUDA%E5%AD%A6%E4%B9%A0/image17045991810275.jpeg">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2023/png/34346540/1695639125136-c9f9b33d-13cb-416f-87da-0ae34854dd35.png#averageHue=%23cfcfcf&clientId=uc2d2df56-381d-4&from=paste&height=91&id=ua65b304c&originHeight=137&originWidth=772&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=13887&status=done&style=none&taskId=u45ba7f0f-c9ec-4316-8851-73a66b4197c&title=&width=514.6666666666666">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2023/png/34346540/1695640550078-fe4b4c71-8a3d-4c48-9be4-dc90d0d068ba.png#averageHue=%23bebebe&clientId=uc2d2df56-381d-4&from=paste&height=525&id=ua1ae4534&originHeight=787&originWidth=1496&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=104314&status=done&style=none&taskId=u92b47243-20b5-475b-9979-64a4ae3a075&title=&width=997.3333333333334">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2023/png/34346540/1695644164506-b2963dd1-97c8-47dd-8af9-665002300dac.png#averageHue=%23e6d4bc&clientId=uc2d2df56-381d-4&from=paste&height=743&id=u842cf6ef&originHeight=1114&originWidth=1484&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=212692&status=done&style=none&taskId=uf27ac98b-eb83-42c9-b528-155c8468202&title=&width=989.3333333333334">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2023/png/34346540/1695645308835-a420d535-3ff3-4038-b80f-419457492506.png#averageHue=%235a5a5a&clientId=uc2d2df56-381d-4&from=paste&height=531&id=u38a4930c&originHeight=797&originWidth=1476&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=64782&status=done&style=none&taskId=u73105c91-fbbd-481a-9097-a1f6f168f59&title=&width=984">
<meta property="og:image" content="https://cdn.nlark.com/yuque/0/2023/png/34346540/1695686956447-746c1898-bb55-40c8-862d-7c12c93b8afe.png#averageHue=%23f7edc7&clientId=ub37ef447-6dda-4&from=paste&id=u62082826&originHeight=592&originWidth=908&originalType=url&ratio=1.5&rotation=0&showTitle=false&size=45187&status=done&style=none&taskId=u2325c7c1-aa9e-4df4-b131-3748df2f760&title=">
<meta property="article:published_time" content="2024-01-06T09:55:00.448Z">
<meta property="article:modified_time" content="2024-01-07T03:53:51.549Z">
<meta property="article:author" content="Lusz">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2024/01/06/CUDA%E5%AD%A6%E4%B9%A0/image2.png">

<link rel="canonical" href="http://example.com/2024/01/06/CUDA%E5%AD%A6%E4%B9%A0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>CUDA | Lusz的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Lusz的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/06/CUDA%E5%AD%A6%E4%B9%A0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Lusz">
      <meta itemprop="description" content="一名优秀的少先队员">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lusz的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CUDA
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-01-06 17:55:00" itemprop="dateCreated datePublished" datetime="2024-01-06T17:55:00+08:00">2024-01-06</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-07 11:53:51" itemprop="dateModified" datetime="2024-01-07T11:53:51+08:00">2024-01-07</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><a target="_blank" rel="noopener" href="https://face2ai.com/">谭升的博客</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/34587739">CUDA编程入门极简教程</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/410278370">CUDA 矩阵乘法终极优化指南</a><br>安装<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/488518526">CUDA开发环境搭建</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/484016885">CUDA入门示例1：两个整型数组相加</a></p>
<h1 id="异构计算"><a href="#异构计算" class="headerlink" title="异构计算"></a>异构计算</h1><p><img src="/2024/01/06/CUDA%E5%AD%A6%E4%B9%A0/image2.png" alt="img"></p>
<p>GPU的ALU更多，逻辑控制单元更少</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">*hello_world.cu</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">hello_world</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;GPU: Hello world!\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> **argv)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;CPU: Hello world!\n&quot;</span>);</span><br><span class="line">  hello_world&lt;&lt;&lt;<span class="number">1</span>,<span class="number">10</span>&gt;&gt;&gt;();</span><br><span class="line">  cudaDeviceReset();<span class="comment">//if no this line ,it can not output hello world from gpu</span></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>cudaDeviceReset()函数</strong>：这句话如果没有，则不能正常的运行，因为这句话包含了<strong>隐式同步</strong>，GPU和CPU执行程序是异步的，核函数调用后成立刻会到主机线程继续，而不管GPU端核函数是否执行完毕，所以上面的程序就是GPU刚开始执行，CPU已经退出程序了，所以我们要等GPU执行完了，再退出主机线程</p>
<p>:::info<br>一般CUDA程序分成下面这些步骤：</p>
<ol>
<li>分配GPU内存</li>
<li>拷贝内存到设备</li>
<li>调用CUDA内核函数来执行计算</li>
<li>把计算完成数据拷贝回主机端</li>
<li>内存销毁</li>
</ol>
<p>上面的hello world只到第三步，没有内存交换。<br>:::</p>
<h1 id="CUDA编程模型概述"><a href="#CUDA编程模型概述" class="headerlink" title="CUDA编程模型概述"></a>CUDA编程模型概述</h1><p>CUDA C是编译型语言，openCL是解释型语言<br><img src="/2024/01/06/CUDA%E5%AD%A6%E4%B9%A0/image.jpeg" alt="img"><br><img src="/2024/01/06/CUDA%E5%AD%A6%E4%B9%A0/image1.jpeg" alt="img"></p>
<p>分层次内存图<br><img src="/2024/01/06/CUDA%E5%AD%A6%E4%B9%A0/image17045991810275.jpeg" alt="img"></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">* https://github.com/Tony-Tan/CUDA_Freshman</span></span><br><span class="line"><span class="comment">* 3_sum_arrays</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;freshman.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">sumArrays</span><span class="params">(<span class="type">float</span> * a,<span class="type">float</span> * b,<span class="type">float</span> * res,<span class="type">const</span> <span class="type">int</span> size)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;size;i+=<span class="number">4</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    res[i]=a[i]+b[i];</span><br><span class="line">    res[i+<span class="number">1</span>]=a[i+<span class="number">1</span>]+b[i+<span class="number">1</span>];</span><br><span class="line">    res[i+<span class="number">2</span>]=a[i+<span class="number">2</span>]+b[i+<span class="number">2</span>];</span><br><span class="line">    res[i+<span class="number">3</span>]=a[i+<span class="number">3</span>]+b[i+<span class="number">3</span>];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">__global__ <span class="type">void</span> <span class="title function_">sumArraysGPU</span><span class="params">(<span class="type">float</span>*a,<span class="type">float</span>*b,<span class="type">float</span>*res)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">int</span> i=threadIdx.x;</span><br><span class="line">  res[i]=a[i]+b[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> **argv)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">int</span> dev = <span class="number">0</span>;</span><br><span class="line">  cudaSetDevice(dev);</span><br><span class="line"></span><br><span class="line">  <span class="type">int</span> nElem=<span class="number">32</span>;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Vector size:%d\n&quot;</span>,nElem);</span><br><span class="line">  <span class="type">int</span> nByte=<span class="keyword">sizeof</span>(<span class="type">float</span>)*nElem;</span><br><span class="line">  <span class="type">float</span> *a_h=(<span class="type">float</span>*)<span class="built_in">malloc</span>(nByte);</span><br><span class="line">  <span class="type">float</span> *b_h=(<span class="type">float</span>*)<span class="built_in">malloc</span>(nByte);</span><br><span class="line">  <span class="type">float</span> *res_h=(<span class="type">float</span>*)<span class="built_in">malloc</span>(nByte);</span><br><span class="line">  <span class="type">float</span> *res_from_gpu_h=(<span class="type">float</span>*)<span class="built_in">malloc</span>(nByte);</span><br><span class="line">  <span class="built_in">memset</span>(res_h,<span class="number">0</span>,nByte);</span><br><span class="line">  <span class="built_in">memset</span>(res_from_gpu_h,<span class="number">0</span>,nByte);</span><br><span class="line"></span><br><span class="line">  <span class="type">float</span> *a_d,*b_d,*res_d;</span><br><span class="line">  CHECK(cudaMalloc((<span class="type">float</span>**)&amp;a_d,nByte));</span><br><span class="line">  CHECK(cudaMalloc((<span class="type">float</span>**)&amp;b_d,nByte));</span><br><span class="line">  CHECK(cudaMalloc((<span class="type">float</span>**)&amp;res_d,nByte));</span><br><span class="line"></span><br><span class="line">  initialData(a_h,nElem);</span><br><span class="line">  initialData(b_h,nElem);</span><br><span class="line"></span><br><span class="line">  CHECK(cudaMemcpy(a_d,a_h,nByte,cudaMemcpyHostToDevice));</span><br><span class="line">  CHECK(cudaMemcpy(b_d,b_h,nByte,cudaMemcpyHostToDevice));</span><br><span class="line"></span><br><span class="line">  dim3 <span class="title function_">block</span><span class="params">(nElem)</span>;</span><br><span class="line">  dim3 <span class="title function_">grid</span><span class="params">(nElem/block.x)</span>;</span><br><span class="line">  sumArraysGPU&lt;&lt;&lt;grid,block&gt;&gt;&gt;(a_d,b_d,res_d);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;Execution configuration&lt;&lt;&lt;%d,%d&gt;&gt;&gt;\n&quot;</span>,block.x,grid.x);</span><br><span class="line"></span><br><span class="line">  CHECK(cudaMemcpy(res_from_gpu_h,res_d,nByte,cudaMemcpyDeviceToHost));</span><br><span class="line">  sumArrays(a_h,b_h,res_h,nElem);</span><br><span class="line"></span><br><span class="line">  checkResult(res_h,res_from_gpu_h,nElem);</span><br><span class="line">  cudaFree(a_d);</span><br><span class="line">  cudaFree(b_d);</span><br><span class="line">  cudaFree(res_d);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">free</span>(a_h);</span><br><span class="line">  <span class="built_in">free</span>(b_h);</span><br><span class="line">  <span class="built_in">free</span>(res_h);</span><br><span class="line">  <span class="built_in">free</span>(res_from_gpu_h);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="grid-stride-loop"><a href="#grid-stride-loop" class="headerlink" title="grid stride loop"></a>grid stride loop</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> stride = blockDim.x * gridDim.x;</span><br></pre></td></tr></table></figure>

<p>当主机启动了核函数，控制权马上回到主机，而不是主机等待设备完成核函数的运行</p>
<h3 id="CUDA中STL的使用"><a href="#CUDA中STL的使用" class="headerlink" title="CUDA中STL的使用"></a>CUDA中STL的使用</h3><p>thrust::device_vector<br>__syncthreads();</p>
<h1 id="CUDA执行模型概述"><a href="#CUDA执行模型概述" class="headerlink" title="CUDA执行模型概述"></a>CUDA执行模型概述</h1><p>因为SM有限，虽然我们的编程模型层面看所有线程都是并行执行的，但是在微观上看，所有线程块也是分批次的在物理层面的机器上执行，线程块里不同的线程可能进度都不一样，但是同一个线程束内的线程拥有相同的进度。<br>并行就会引起竞争，多线程以未定义的顺序访问同一个数据，就导致了不可预测的行为，CUDA只提供了一种块内同步的方式，块之间没办法同步！<br>同一个SM上可以有不止一个常驻的线程束，有些在执行，有些在等待，他们之间状态的转换是不需要开销的</p>
<h2 id="理解线程数运行的本质"><a href="#理解线程数运行的本质" class="headerlink" title="理解线程数运行的本质"></a>理解线程数运行的本质</h2><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34346540/1695639125136-c9f9b33d-13cb-416f-87da-0ae34854dd35.png#averageHue=%23cfcfcf&clientId=uc2d2df56-381d-4&from=paste&height=91&id=ua65b304c&originHeight=137&originWidth=772&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=13887&status=done&style=none&taskId=u45ba7f0f-c9ec-4316-8851-73a66b4197c&title=&width=514.6666666666666"></p>
<h3 id="线程块的分化"><a href="#线程块的分化" class="headerlink" title="线程块的分化"></a>线程块的分化</h3><p>把都执行if的线程塞到一个线程束中，或者让一个线程束中的线程都执行if，另外线程都执行else的这种方式可以将效率提高很多，方法2比方法1高效</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">mathKernel1</span><span class="params">(<span class="type">float</span> *c)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">int</span> tid = blockIdx.x* blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line">	<span class="type">float</span> a = <span class="number">0.0</span>;</span><br><span class="line">	<span class="type">float</span> b = <span class="number">0.0</span>;</span><br><span class="line">	<span class="keyword">if</span> (tid % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		a = <span class="number">100.0f</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">	&#123;</span><br><span class="line">		b = <span class="number">200.0f</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	c[tid] = a + b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">__global__ <span class="type">void</span> <span class="title function_">mathKernel2</span><span class="params">(<span class="type">float</span> *c)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="type">int</span> tid = blockIdx.x* blockDim.x + threadIdx.x;</span><br><span class="line">	<span class="type">float</span> a = <span class="number">0.0</span>;</span><br><span class="line">	<span class="type">float</span> b = <span class="number">0.0</span>;</span><br><span class="line">	<span class="keyword">if</span> ((tid/warpSize) % <span class="number">2</span> == <span class="number">0</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		a = <span class="number">100.0f</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">	&#123;</span><br><span class="line">		b = <span class="number">200.0f</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	c[tid] = a + b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.nlark.com/yuque/0/2023/png/34346540/1695640550078-fe4b4c71-8a3d-4c48-9be4-dc90d0d068ba.png#averageHue=%23bebebe&clientId=uc2d2df56-381d-4&from=paste&height=525&id=ua1ae4534&originHeight=787&originWidth=1496&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=104314&status=done&style=none&taskId=u92b47243-20b5-475b-9979-64a4ae3a075&title=&width=997.3333333333334" alt="image.png"><br>联合编译<br><a target="_blank" rel="noopener" href="https://www.codenong.com/cs106714208/">https://www.codenong.com/cs106714208/</a><br>当块大小超过硬件的极限，并没有报错，而是返回了错误值</p>
<p>在博客中，dev-&gt;host似乎不需要同步，而host-&gt;dev似乎需要同步</p>
<h2 id="避免分支分化"><a href="#避免分支分化" class="headerlink" title="避免分支分化"></a>避免分支分化</h2><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34346540/1695644164506-b2963dd1-97c8-47dd-8af9-665002300dac.png#averageHue=%23e6d4bc&clientId=uc2d2df56-381d-4&from=paste&height=743&id=u842cf6ef&originHeight=1114&originWidth=1484&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=212692&status=done&style=none&taskId=uf27ac98b-eb83-42c9-b528-155c8468202&title=&width=989.3333333333334" alt="image.png"></p>
<h2 id="循环展开"><a href="#循环展开" class="headerlink" title="循环展开"></a>循环展开</h2><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34346540/1695645308835-a420d535-3ff3-4038-b80f-419457492506.png#averageHue=%235a5a5a&clientId=uc2d2df56-381d-4&from=paste&height=531&id=u38a4930c&originHeight=797&originWidth=1476&originalType=binary&ratio=1.5&rotation=0&showTitle=false&size=64782&status=done&style=none&taskId=u73105c91-fbbd-481a-9097-a1f6f168f59&title=&width=984" alt="image.png"></p>
<p>循环展开后面的没太看</p>
<h1 id="内存模型概述"><a href="#内存模型概述" class="headerlink" title="内存模型概述"></a>内存模型概述</h1><p>全局内存访问是对齐，也就是一次要读取指定大小（32，64，128）整数倍字节的内存<br><img src="https://cdn.nlark.com/yuque/0/2023/png/34346540/1695686956447-746c1898-bb55-40c8-862d-7c12c93b8afe.png#averageHue=%23f7edc7&clientId=ub37ef447-6dda-4&from=paste&id=u62082826&originHeight=592&originWidth=908&originalType=url&ratio=1.5&rotation=0&showTitle=false&size=45187&status=done&style=none&taskId=u2325c7c1-aa9e-4df4-b131-3748df2f760&title=" alt="image.png"></p>
<h2 id="4-3合并内存访问✨"><a href="#4-3合并内存访问✨" class="headerlink" title="4.3合并内存访问✨"></a>4.3合并内存访问✨</h2>
    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/01/06/hello-world/" rel="prev" title="Hello World">
      <i class="fa fa-chevron-left"></i> Hello World
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/01/07/CUSPARSE/" rel="next" title="CUSPARSE">
      CUSPARSE <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97"><span class="nav-number">1.</span> <span class="nav-text">异构计算</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0"><span class="nav-number">2.</span> <span class="nav-text">CUDA编程模型概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#grid-stride-loop"><span class="nav-number">2.0.1.</span> <span class="nav-text">grid stride loop</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CUDA%E4%B8%ADSTL%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">2.0.2.</span> <span class="nav-text">CUDA中STL的使用</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CUDA%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0"><span class="nav-number">3.</span> <span class="nav-text">CUDA执行模型概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%90%86%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%95%B0%E8%BF%90%E8%A1%8C%E7%9A%84%E6%9C%AC%E8%B4%A8"><span class="nav-number">3.1.</span> <span class="nav-text">理解线程数运行的本质</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E5%9D%97%E7%9A%84%E5%88%86%E5%8C%96"><span class="nav-number">3.1.1.</span> <span class="nav-text">线程块的分化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%81%BF%E5%85%8D%E5%88%86%E6%94%AF%E5%88%86%E5%8C%96"><span class="nav-number">3.2.</span> <span class="nav-text">避免分支分化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BE%AA%E7%8E%AF%E5%B1%95%E5%BC%80"><span class="nav-number">3.3.</span> <span class="nav-text">循环展开</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E6%A6%82%E8%BF%B0"><span class="nav-number">4.</span> <span class="nav-text">内存模型概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3%E5%90%88%E5%B9%B6%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E2%9C%A8"><span class="nav-number">4.1.</span> <span class="nav-text">4.3合并内存访问✨</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Lusz</p>
  <div class="site-description" itemprop="description">一名优秀的少先队员</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Lusz</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
